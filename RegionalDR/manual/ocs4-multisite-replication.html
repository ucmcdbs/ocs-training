<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Manual OpenShift Regional Disaster Recovery :: OCS Training</title>
    <link rel="canonical" href="https://red-hat-storage.github.io/ocs-training/RegionalDR/manual/ocs4-multisite-replication.html">
    <meta name="generator" content="Antora 2.3.4">
    <link rel="stylesheet" href="../../_/css/site.css">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-LGCEEZGN54"></script>
    <script>function gtag(){dataLayer.push(arguments)};window.dataLayer=window.dataLayer||[];gtag('js',new Date());gtag('config','G-LGCEEZGN54')</script>
    <script>var uiRootPath = '../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage" target="_blank">
          <img src="../../_/img/header_logo_reverse.svg" height="40px" alt="Red Hat Data Services">
      </a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Get Help</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_container_storage" target="_blank">OCS Documentation</a>
            <a class="navbar-item" href="https://bugzilla.redhat.com/describecomponents.cgi?product=Red%20Hat%20OpenShift%20Container%20Storage" target="_blank">Browse Bugs</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Improve Guides</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/red-hat-storage/ocs-training/blob/master/CONTRIBUTING.adoc" target="_blank">Guidelines</a>
            <a class="navbar-item" href="https://github.com/red-hat-storage/ocs-training/issues/new/choose" target="_blank">Open Issue</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">More Infos</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://www.redhat.com/en/blog/channel/red-hat-storage" target="_blank">Our Blog</a>
            <a class="navbar-item" href="https://www.youtube.com/channel/UCoyG8VyvB-XUxQl1mD3T3Gw" target="_blank">Youtube</a>
            <a class="navbar-item" href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage" target="_blank">OCS Technology</a>
          </div>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="RegionalDR" data-version="master">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">ODF Regional DR</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../../training/index.html">Back to general ODF documents</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">RDRhelper</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../helper/requirements.html">Requirements for the RDRhelper</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../helper/install.html">Install RDRhelper</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../helper/usage.html">Use RDRhelper</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Manual steps</span>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="ocs4-multisite-replication.html">Manual RegionalDR</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">ODF Regional DR</span>
    <span class="version">master</span>
  </div>
  <ul class="components">
    <li class="component">
      <a class="title" href="../../training/index.html">OCS Installation and Configuration</a>
      <ul class="versions">
        <li class="version is-latest">
          <a href="../../training/index.html">master</a>
        </li>
      </ul>
    </li>
    <li class="component is-current">
      <a class="title" href="../index.html">ODF Regional DR</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">master</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../../training/index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">ODF Regional DR</a></li>
    <li>Manual steps</li>
    <li><a href="ocs4-multisite-replication.html">Manual RegionalDR</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="https://github.com/red-hat-data-services/RDRhelper/edit/master/docs/modules/manual/pages/ocs4-multisite-replication.adoc">Edit this Page</a></div>
  </div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Manual OpenShift Regional Disaster Recovery</h1>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_overview">1. Overview</a>
<ul class="sectlevel2">
<li><a href="#_openshift_multisite_connectivity">1.1. OpenShift Multisite Connectivity</a>
<ul class="sectlevel3">
<li><a href="#_submariner_prerequisites">1.1.1. Submariner Prerequisites</a>
<ul class="sectlevel4">
<li><a href="#_on_aws_clusters">On AWS clusters</a></li>
<li><a href="#_on_non_aws_clusters">On non-AWS clusters</a></li>
<li><a href="#_on_all_platforms">On all platforms</a></li>
</ul>
</li>
<li><a href="#_submariner_installation">1.1.2. Submariner Installation</a>
<ul class="sectlevel4">
<li><a href="#_verifying_submariner_connectivity">Verifying Submariner connectivity</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_configuring_multisite_storage_replication">1.2. Configuring Multisite Storage Replication</a>
<ul class="sectlevel3">
<li><a href="#_openshift_data_foundation_installation">1.2.1. OpenShift Data Foundation Installation</a></li>
<li><a href="#_configuring_rbd_mirroring_between_odf_clusters">1.2.2. Configuring RBD Mirroring between ODF clusters</a>
<ul class="sectlevel4">
<li><a href="#_enable_omap_generator">Enable OMAP Generator</a></li>
<li><a href="#_create_ceph_pools_for_replication">Create Ceph Pools for replication</a></li>
<li><a href="#_bootstrap_peer_clusters">Bootstrap Peer Clusters</a></li>
<li><a href="#_create_rbd_mirror_custom_resource">Create RBD Mirror Custom Resource</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_creating_mirror_storage_class_and_sample_application">1.3. Creating Mirror storage class and Sample application</a>
<ul class="sectlevel3">
<li><a href="#_storageclass_for_volume_replication">1.3.1. Storageclass for volume replication</a></li>
<li><a href="#_sample_application">1.3.2. Sample Application</a></li>
</ul>
</li>
<li><a href="#_installing_oadp_for_kubernetes_resource_collection">1.4. Installing OADP for Kubernetes resource collection</a>
<ul class="sectlevel3">
<li><a href="#_installing_oadp_from_operatorhub">1.4.1. Installing OADP from OperatorHub</a></li>
<li><a href="#_creating_bucket_credentials_secret">1.4.2. Creating bucket credentials secret</a></li>
<li><a href="#_creating_velero_resource">1.4.3. Creating Velero resource</a></li>
</ul>
</li>
<li><a href="#_failover_to_secondary_cluster">1.5. Failover to Secondary cluster</a>
<ul class="sectlevel3">
<li><a href="#_installing_the_toolbox_for_ceph_commands">1.5.1. Installing the toolbox for Ceph commands</a></li>
<li><a href="#_enable_volumes_for_snapshot_replication">1.5.2. Enable volumes for snapshot replication</a></li>
<li><a href="#_creating_kubernetes_resource_backup">1.5.3. Creating Kubernetes resource backup</a></li>
<li><a href="#_scaling_application_down_on_primary_cluster">1.5.4. Scaling application down on primary cluster</a></li>
<li><a href="#_demoting_and_promoting_storage_to_alternate_site">1.5.5. Demoting and Promoting storage to alternate site</a></li>
<li><a href="#_restoring_application_to_secondary_cluster">1.5.6. Restoring application to secondary cluster</a></li>
<li><a href="#_verifying_application">1.5.7. Verifying application</a></li>
</ul>
</li>
<li><a href="#_failback_to_primary_cluster">1.6. Failback to Primary cluster</a></li>
</ul>
</li>
</ul>
</div>
<div class="sect1">
<h2 id="_overview"><a class="anchor" href="#_overview"></a>1. Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The intent of this guide is to detail the steps and commands necessary to be able to failover an application from one <code>OpenShift Container Platform</code> (OCP) cluster to another and then failback the same application to the original <strong>primary cluster</strong>.</p>
</div>
<div class="paragraph">
<p>The necessary components are two OCP 4.6 (or greater) clusters, connectivity between their private networks, and <code>OpenShift Data Foundation</code> (ODF) installed on both OCP clusters. ODF version <strong>4.7</strong> (or greater) is required for the <code>RBD Mirroring</code> feature to provide regional asynchronous replication between the two clusters. In order to also replicate the Kubernetes resources (pods, services, routes, etc.) from one cluster to another, this guide will make use of the Velero <code>Backup</code> and <code>Restore</code> APIs exposed via the OCP community operator <code>OpenShift APIs for Data Protection</code> or <code>OADP</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Starting April 2021, <code>OpenShift Container Storage</code> (OCS) has been rebranded to <code>OpenShift Data Foundation</code> (ODF).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This is a general overview of the steps required to configure and execute <code>Regional Disaster Recovery</code> capabilities using ODF <strong>4.7</strong> and <code>OADP</code> across two distinct OCP clusters separated by distance.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These steps are considered Dev Preview in ODF 4.7, and are provided for POCs purposes. They will be supported for production usage in a later ODF release.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic" start="1">
<li>
<p><strong>Ensure clusters have unique private network address ranges.</strong><br>
Ensure the primary and secondary OCP clusters have unique private network address ranges.</p>
</li>
<li>
<p><strong>Connect the two private networks.</strong><br>
Connect the private networks (cluster and service) using submariner.</p>
</li>
<li>
<p><strong>Install ODF 4.7.</strong><br>
Install ODF 4.7 on primary and secondary OCP clusters and validate deployment.</p>
</li>
<li>
<p><strong>Create new CephBlockPool.</strong><br>
To clearly keep mirrored volumes separate from any production volumes in this POC, we will create a new CephBlockPool on both primary and secondary OCP clusters. We will limit RBD Mirroring to only RBD volumes from within this new pool.</p>
</li>
<li>
<p><strong>Configure peer relationship between clusters.</strong><br>
Configure peer relationship between ODF clusters and create RBD Mirroring daemons.</p>
</li>
<li>
<p><strong>Create new StorageClass.</strong><br>
To clearly keep mirrored PVs separate from any production PVs in this POC, we will create a new StorageClass for PVCs that will have mirroring enabled.</p>
</li>
<li>
<p><strong>Configure target apps to claim PVCs from new StorageClass.</strong><br>
In the example, we will create a Sample Application which will use a single PVC claimed from the StorageClass mirror.</p>
</li>
<li>
<p><strong>Install OADP (OpenShift API for Data Protection).</strong><br>
Using OperatorHub, install OADP on both OCP clusters. We will use OADP for copying target application metadata resources (Kubernetes CRs) from the primary to the secondary OCP cluster.</p>
</li>
<li>
<p><strong>Install Ceph toolbox.</strong><br>
Install the Ceph toolbox on primary and secondary clusters to make Ceph CLI commands available. Ceph CLI commands will be used for enabling PVC mirroring, and for promoting/demoting each half of a mirror to be primary or secondary.</p>
</li>
<li>
<p><strong>Enable mirroring on each PVC.</strong><br>
On the primary cluster, use the Ceph CLI to enable PV mirroring for each target PVC. (Our Sample Application has only a single PVC.)</p>
</li>
<li>
<p><strong>Backup OpenShift resources to S3 target.</strong><br>
Using the Backup API from OADP, we will backup all Kubernetes resources (CRs) for the Sample Application on the primary cluster to a S3 compatible object bucket.</p>
</li>
<li>
<p><strong>Simulate cluster failure event on the primary cluster.</strong><br>
In our example, we will simulate a failure event simply by scaling the deployment(s) for our Sample Application to zero. This makes the application on the primary cluster unavailable.</p>
</li>
<li>
<p><strong>Demote and promote each PVC.</strong><br>
On the primary cluster, demote each target PVC being mirrored. On the secondary cluster, promote each target PVC. (Our Sample Application has only a single PVC.)</p>
</li>
<li>
<p><strong>Restore OpenShift resources from S3 target</strong>.<br>
Using OADP and the Restore API copy all Kubernetes resources for the <code>Sample Application</code> from the <code>S3</code> combatible object bucket to the secondary cluster. The Backup and Restore could be scheduled to run at a desired frequency to ensure that the secondary cluster always has the most recent metadata from the applications targeted for failover on the primary cluster.</p>
</li>
<li>
<p><strong>Verify application availability on the secondary cluster.</strong><br>
Verify the Sample Application now is operational on the secondary cluster and that new data can be saved.</p>
</li>
</ol>
</div>
<div class="sect2">
<h3 id="_openshift_multisite_connectivity"><a class="anchor" href="#_openshift_multisite_connectivity"></a>1.1. OpenShift Multisite Connectivity</h3>
<div class="paragraph">
<p>For this solution to work the OpenShift SDNs (Software Defined Networks) must be connected so that <code>OpenShift Data Foundation</code> (ODF) resources can communicate. In particular there needs to be network connectivity between the RBD Mirror <strong>POD</strong> or daemon deployed in each cluster.</p>
</div>
<div class="paragraph">
<p>There are various ways to connect the private SDNs and the choice for this guide is to use <code>Submariner</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Whatever way the OCP clusters are connected, the default <code>IP CIDRs</code> (Classless inter-domain routing) for cluster and service networking must be modified to be different on one of the clusters to avoid addressing conflicts.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>Submariner</code> consists of several main components that work in conjunction to securely connect workloads across multiple Kubernetes or OCP clusters, both on-premises and in public clouds. They are the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Gateway Engine: manages the secure tunnels to other clusters.</p>
</li>
<li>
<p>Route Agent: routes cross-cluster traffic from nodes to the active Gateway Engine.</p>
</li>
<li>
<p>Broker: facilitates the exchange of metadata between Gateway Engines enabling them to discover one another.</p>
</li>
<li>
<p>Service Discovery: provides DNS discovery of Services across clusters.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><code>Submariner</code> does support connecting  OCP clusters installed on AWS. There is also support for connecting non-AWS OCP clusters such as those installed on VMware or Bare Metal (BM). Hybrid connectivity of one OCP cluster on AWS and the 2nd cluster on non-AWS (i.e. VMware) infrastructure is also possible.</p>
</div>
<div class="paragraph">
<p>For more information on <code>Submariner</code> and the different configuration options go to <a href="https://submariner.io/getting-started" class="bare">submariner.io/getting-started</a>.</p>
</div>
<div class="sect3">
<h4 id="_submariner_prerequisites"><a class="anchor" href="#_submariner_prerequisites"></a>1.1.1. Submariner Prerequisites</h4>
<div class="paragraph">
<p>There are a few prerequisites to deploy <code>Submariner</code>. The first requirement is to modify the <strong>install-config.yaml</strong> configuration used with <strong>openshift-install</strong> before installing OpenShift so that the IP ranges for the cluster and service networks will be different as shown in examples below.</p>
</div>
<div class="paragraph">
<p>Example for <code>site1</code> <strong>install-config.yaml</strong>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">[...]
metadata:
  name: site1
networking:
  clusterNetwork:
  - cidr: 10.6.0.0/16       <i class="conum" data-value="1"></i><b>(1)</b>
    hostPrefix: 23
  machineCIDR: 10.0.0.0/16
  networkType: OpenShiftSDN
  serviceNetwork:
  - 10.16.0.0/16            <i class="conum" data-value="2"></i><b>(2)</b>
[...]</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>clusterNetwork for site1</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>serviceNetwork for site1</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Example for <code>site2</code> <strong>install-config.yaml</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">[...]
metadata:
  name: site2
networking:
  clusterNetwork:
  - cidr: 10.12.0.0/16      <i class="conum" data-value="1"></i><b>(1)</b>
    hostPrefix: 23
  machineCIDR: 10.0.0.0/16
  networkType: OpenShiftSDN
  serviceNetwork:
  - 10.112.0.0/16           <i class="conum" data-value="2"></i><b>(2)</b>
[...]</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>clusterNetwork for site2</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>serviceNetwork for site2</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you already have your OCP clusters deployed, you can check your clusterNetwork and serviceNetwork configuration using the following command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get networks.config.openshift.io cluster -o json | jq .spec</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
  "clusterNetwork": [
    {
      "cidr": "10.5.0.0/16",
      "hostPrefix": 23
    }
  ],
  "externalIP": {
    "policy": {}
  },
  "networkType": "OpenShiftSDN",
  "serviceNetwork": [
    "10.15.0.0/16"
  ]
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Once the two OCP clusters are created, note the location of their unique <code>kubeconfig</code> (i.e.~/site1/auth/kubeconfig).
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="_on_aws_clusters"><a class="anchor" href="#_on_aws_clusters"></a>On AWS clusters</h5>
<div class="paragraph">
<p>For installing <code>Submariner</code> on AWS the <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html">AWS Command Line Interface</a> needs to be installed on your deploy host.</p>
</div>
<div class="paragraph">
<p>Refer to these links for additional information about prerequisites when at least one OCP instance is installed on AWS.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://submariner.io/getting-started/quickstart/openshift/aws" class="bare">submariner.io/getting-started/quickstart/openshift/aws</a></p>
</li>
<li>
<p><a href="https://submariner.io/getting-started/quickstart/openshift/vsphere-aws" class="bare">submariner.io/getting-started/quickstart/openshift/vsphere-aws</a></p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_on_non_aws_clusters"><a class="anchor" href="#_on_non_aws_clusters"></a>On non-AWS clusters</h5>
<div class="paragraph">
<p>For non-AWS OCP clusters the only requirement is to download and install the <code>subctl</code> client that will be used for most <code>Submariner</code> commands.</p>
</div>
</div>
<div class="sect4">
<h5 id="_on_all_platforms"><a class="anchor" href="#_on_all_platforms"></a>On all platforms</h5>
<div class="paragraph">
<p>Install the <code>subctl</code> to install and maintain the submariner installation</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -Ls https://get.submariner.io | bash</code></pre>
</div>
</div>
<div class="paragraph">
<p>And export the path to <code>subctl</code>:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export PATH=$PATH:~/.local/bin</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Add exported path for <code>subctl</code> in your deploy host <code>.profile</code> or <code>.bashrc</code>.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_submariner_installation"><a class="anchor" href="#_submariner_installation"></a>1.1.2. Submariner Installation</h4>
<div class="paragraph">
<p>The <code>Submariner</code> installation detailed in this guide is for two non-AWS OCP clusters installed on VMware.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
Make sure to delete any prior <code>broker-info.subm</code> file before creating a new <code>broker-info.subm</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
All <code>subctl</code> commands can be executed from any node that has network access to the API endpoint for both clusters
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Start by deploying the <code>broker</code>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">subctl deploy-broker --kubeconfig site1/auth/kubeconfig</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre> ✓ Setting up broker RBAC
 ✓ Deploying the Submariner operator
 ✓ Created operator CRDs
 ✓ Created operator namespace: submariner-operator
 ✓ Created operator service account and role
 ✓ Updated the privileged SCC
 ✓ Created lighthouse service account and role
 ✓ Updated the privileged SCC
 ✓ Created Lighthouse service accounts and roles
 ✓ Deployed the operator successfully
 ✓ Deploying the broker
 ✓ The broker has been deployed
 ✓ Creating broker-info.subm file
 ✓ A new IPsec PSK will be generated for broker-info.subm</pre>
</div>
</div>
<div class="paragraph">
<p>Now we want to create the connection between the two OCP clusters. The <code>gateway</code> <strong>Pod</strong> will be created on the node selected from the displayed list of available nodes during the <code>subctl join</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>--natt=false</code> flag is used when the connection between the two OCP clusters does not involve <code>NAT</code> (Network Address Translation). Reference <a href="https://submariner.io/operations/deployment">Submariner documentation</a> for how to <code>subctl join</code> OCP clusters using <code>NAT</code>.
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">subctl join --kubeconfig site1/auth/kubeconfig --clusterid site1 broker-info.subm --natt=false</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>* broker-info.subm says broker is at: https://api.site1.chris.ocs.ninja:6443
? Which node should be used as the gateway? site1-fqldq-worker-975qq
⢄⡱ Discovering network details     Discovered network details:
        Network plugin:  OpenShiftSDN
        Service CIDRs:   [10.16.0.0/16]
        Cluster CIDRs:   [10.6.0.0/16]
 ✓ Discovering network details
 ✓ Validating Globalnet configurations
 ✓ Discovering multi cluster details
 ✓ Deploying the Submariner operator
 ✓ Created Lighthouse service accounts and roles
 ✓ Creating SA for cluster
 ✓ Deploying Submariner
 ✓ Submariner is up and running</pre>
</div>
</div>
<div class="paragraph">
<p>Next, do a similar command for <code>site2</code>. The displayed list of available nodes for the <code>gateway</code> <strong>Pod</strong> will be those for the <code>site2</code> OCP instance.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">subctl join --kubeconfig site2/auth/kubeconfig --clusterid site2 broker-info.subm --natt=false</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>* broker-info.subm says broker is at: https://api.site1.chris.ocs.ninja:6443
? Which node should be used as the gateway? site2-lc8kr-worker-8j2qk
⢄⡱ Discovering network details     Discovered network details:
        Network plugin:  OpenShiftSDN
        Service CIDRs:   [10.112.0.0/16]
        Cluster CIDRs:   [10.12.0.0/16]
 ✓ Discovering network details
 ✓ Validating Globalnet configurations
 ✓ Discovering multi cluster details
 ✓ Deploying the Submariner operator
 ✓ Created operator CRDs
 ✓ Created operator namespace: submariner-operator
 ✓ Created operator service account and role
 ✓ Updated the privileged SCC
 ✓ Created lighthouse service account and role
 ✓ Updated the privileged SCC
 ✓ Created Lighthouse service accounts and roles
 ✓ Deployed the operator successfully
 ✓ Creating SA for cluster
 ✓ Deploying Submariner
 ✓ Submariner is up and running</pre>
</div>
</div>
<div class="paragraph">
<p>On the <code>site1</code> OCP that you are logged into you can validate that the <code>Submariner</code> <strong>Pods</strong> are running. The same <strong>Pods</strong> should be <code>Running</code> in <code>site2</code> in the <code>submariner-operator</code> project.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get pods -n submariner-operator --kubeconfig site1/auth/kubeconfig</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>NAME                                            READY   STATUS    RESTARTS   AGE
submariner-gateway-kthdc                        1/1     Running   0          28m
submariner-lighthouse-agent-6c5755764-hjhsm     1/1     Running   0          27m
submariner-lighthouse-coredns-c4f7b6b8c-7nqxz   1/1     Running   0          27m
submariner-lighthouse-coredns-c4f7b6b8c-nt2rl   1/1     Running   0          27m
submariner-operator-6df7c9d659-9d9pm            1/1     Running   0          28m
submariner-routeagent-b476m                     1/1     Running   0          27m
submariner-routeagent-bchnj                     1/1     Running   0          27m
submariner-routeagent-glmlj                     1/1     Running   0          27m
submariner-routeagent-qgdps                     1/1     Running   0          27m
submariner-routeagent-sl2tr                     1/1     Running   0          27m
submariner-routeagent-smmdt                     1/1     Running   0          27m</pre>
</div>
</div>
<div class="sect4">
<h5 id="_verifying_submariner_connectivity"><a class="anchor" href="#_verifying_submariner_connectivity"></a>Verifying Submariner connectivity</h5>
<div class="paragraph">
<p>The last step is to validate the connection between the two OCP clusters using a <code>subctl verify</code> command.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">subctl verify site1/auth/kubeconfig site2/auth/kubeconfig --only connectivity --verbose</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>Performing the following verifications: connectivity
Running Suite: Submariner E2E suite
===================================
Random Seed: 1614875124
Will run 17 of 34 specs
[...]
------------------------------

Ran 11 of 34 Specs in 159.666 seconds
SUCCESS! -- 11 Passed | 0 Failed | 0 Pending | 23 Skipped</pre>
</div>
</div>
<div class="paragraph">
<p>You can also verify the connectivity using site specific kubeconfig and <code>subctl show connections</code>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">subctl show connections --kubeconfig site1/auth/kubeconfig | egrep 'connect|error'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>site2-wsj9g-worker-4c446  site2    10.70.56.142  no   libreswan     10.112.0.0/16, 10.12.0.0/16  connected  560.701µ
[...]</pre>
</div>
</div>
<div class="paragraph">
<p>And then using <code>site2</code> kubeconfig.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">subctl show connections --kubeconfig site2/auth/kubeconfig | egrep 'connect|error'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>site1-vwgpp-worker-fd4gs  site1    10.70.56.202  no   libreswan     10.16.0.0/16, 10.6.0.0/16  connected  459.831µs
[...]</pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
If either site has a <strong><em>connecting</em></strong> or <strong><em>error</em></strong> status instead of <strong><em>connected</em></strong> status there is something wrong with the multisite connectivity. Only proceed after both ways show <strong><em>connected</em></strong>. Reference <a href="https://submariner.io/operations/troubleshooting">Submariner Troubleshooting documentation</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Now that the two OCP instances have their <code>clusterNetwork</code> and <code>serviceNetwork</code> connected the next step is to install <code>OpenShift Data Foundation</code> version <strong>4.7</strong> and configure storage replication or <code>RDB Mirroring</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
For the rest of the instructions <code>site1</code> will be referred to as the OCP <strong>primary cluster</strong> and <code>site2</code> will be referred to as OCP <strong>secondary cluster</strong>.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_configuring_multisite_storage_replication"><a class="anchor" href="#_configuring_multisite_storage_replication"></a>1.2. Configuring Multisite Storage Replication</h3>
<div class="paragraph">
<p>Mirroring is configured on a per-pool basis within peer clusters and can be configured on a specific subset of images within the pool. The <code>rbd-mirror</code> daemon is responsible for pulling image updates from the remote peer cluster and applying them to the image within the local cluster.</p>
</div>
<div class="sect3">
<h4 id="_openshift_data_foundation_installation"><a class="anchor" href="#_openshift_data_foundation_installation"></a>1.2.1. OpenShift Data Foundation Installation</h4>
<div class="paragraph">
<p>In order to configure storage replication between the two OCP instances <code>OpenShift Data Foundation</code> (ODF) must be installed first. Documentation for the deployment can be found at <a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_container_storage" class="bare">access.redhat.com/documentation/en-us/red_hat_openshift_container_storage</a>.</p>
</div>
<div class="paragraph">
<p>ODF deployment guides and instructions are specific to your infrastructure (i.e. AWS, VMware, BM, Azure, etc.). Install ODF version <strong>4.7</strong> or greater on both OCP clusters.</p>
</div>
<div class="paragraph">
<p>You can validate the successful deployment of ODF on each OCP instance with the following command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get storagecluster -n openshift-storage ocs-storagecluster -o jsonpath='{.status.phase}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>If result is <code>Ready</code> on <strong>primary cluster</strong> and <strong>secondary cluster</strong> you are ready to continue.</p>
</div>
</div>
<div class="sect3">
<h4 id="_configuring_rbd_mirroring_between_odf_clusters"><a class="anchor" href="#_configuring_rbd_mirroring_between_odf_clusters"></a>1.2.2. Configuring RBD Mirroring between ODF clusters</h4>
<div class="paragraph">
<p>The next step will be to create the mirroring relationship between the two ODF clusters so the RBD volumes or images created using the Ceph RBD storageclass can be replicated from one OCP cluster to the other OCP cluster.</p>
</div>
<div class="sect4">
<h5 id="_enable_omap_generator"><a class="anchor" href="#_enable_omap_generator"></a>Enable OMAP Generator</h5>
<div class="paragraph">
<p>Omap generator is a sidecar container that, when deployed with the CSI provisioner pod, generates the internal CSI omaps between the PV and the RBD image. The name of the new container is <code>csi-omap-generator</code>. This is required as static <strong>PVs</strong> are transferred across peer clusters in the DR use case, and hence is needed to preserve <strong>PVC</strong> to storage mappings.</p>
</div>
<div class="paragraph">
<p>Execute these steps on the <strong>primary cluster</strong> and the <strong>seconday cluster</strong> to enable the OMAP generator.</p>
</div>
<div class="paragraph">
<p>Edit the rook-ceph-operator-config configmap and add <code>CSI_ENABLE_OMAP_GENERATOR</code> set to true.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc patch cm rook-ceph-operator-config -n openshift-storage --type json --patch  '[{ "op": "add", "path": "/data/CSI_ENABLE_OMAP_GENERATOR", "value": "true" }]'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>configmap/rook-ceph-operator-config patched</pre>
</div>
</div>
<div class="paragraph">
<p>Validate that there are now 7 sidecar containers and that the <code>csi-omap-generator</code> container is now running.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get pods -n openshift-storage -l app=csi-rbdplugin-provisioner -o jsonpath={.items[*].spec.containers[*].name}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>csi-provisioner csi-resizer csi-attacher csi-snapshotter csi-omap-generator csi-rbdplugin liveness-prometheus csi-provisioner csi-resizer csi-attacher csi-snapshotter csi-omap-generator csi-rbdplugin liveness-prometheus</pre>
</div>
</div>
<div class="paragraph">
<p>There are two <code>csi-rbdplugin-provisioner</code> pods for availability so there should be two groups of the same 7 containers for each pod.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Repeat these steps for the <strong>secondary cluster</strong> before proceeding and also repeat the validation for the new <code>csi-omap-generator</code> container.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_create_ceph_pools_for_replication"><a class="anchor" href="#_create_ceph_pools_for_replication"></a>Create Ceph Pools for replication</h5>
<div class="paragraph">
<p>In this section you will create a new <strong>CephBlockPool</strong> that is RBD mirroring enabled. Execute the steps on each of the OCP clusters to enable mirroring and configure the <code>snapshot</code> schedule for images.</p>
</div>
<div class="paragraph">
<p>Sample Ceph block pool that has mirroring enabled:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: ceph.rook.io/v1
kind: CephBlockPool
metadata:
   name: replicapool
   namespace: openshift-storage
spec:
   replicated:
     size: 3
   mirroring:
     enabled: true
     mode: image
       # specify the schedules on which snapshots should be taken
     snapshotSchedules:
       - interval: 5m
       #  startTime: 00:00:00-05:00
   statusCheck:
     mirror:
       disabled: false
       interval: 60s</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>snapshotSchedules</code> is a global value for the specific <strong>CephBlockPool</strong> used to configure the snapshot interval between peers for <code>mirror-enabled</code> volumes in this pool. It can be as shorter if desired (i.e., 60s).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Now create new <strong>CephBlockPool</strong>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/red-hat-data-services/RDRhelper/master/docs/modules/manual/attachments/replicapool.yaml | oc apply -f -</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>cephblockpool.ceph.rook.io/replicapool created</pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Repeat the steps on the OCP <strong>secondary cluster</strong>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_bootstrap_peer_clusters"><a class="anchor" href="#_bootstrap_peer_clusters"></a>Bootstrap Peer Clusters</h5>
<div class="paragraph">
<p>In order for the <code>rbd-mirror</code> daemon to discover its peer cluster, the peer must be registered and a user account must be created. The following steps enables <code>Bootstrapping</code> peers to discover and authenticate to each other.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Execute the following commands on the <strong>secondary cluster</strong> first.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To determine the name of the <code>rbd-mirror</code> secret that contains the bootstrap secret do the following:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc --kubeconfig site2/auth/kubeconfig get cephblockpool.ceph.rook.io/replicapool -n openshift-storage -ojsonpath='{.status.info.rbdMirrorBootstrapPeerSecretName}{"\n"}'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>pool-peer-token-replicapool</pre>
</div>
</div>
<div class="paragraph">
<p>The secret <code>pool-peer-token-replicapool</code> contains all the information related to the token and needs to be injected into the peer. To find the decoded secret do the following:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc --kubeconfig site2/auth/kubeconfig get secrets pool-peer-token-replicapool -n openshift-storage -o jsonpath='{.data.token}' | base64 -d</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>eyJmc2lkIjoiYjg4OGRlNjEtODUyMC00MzgxLWE4ODMtMzY2ZTY0YmQ0MDBmIiwiY2xpZW50X2lkIjoicmJkLW1pcnJvci1wZWVyIiwia2V5IjoiQVFDOCtWTmdkNURnQkJBQUd5S0l0VE9ac3FneVM3SEMrTXh5bGc9PSIsIm1vbl9ob3N0IjoiW3YyOjEwLjExMi43MS4xNTU6MzMwMCx2MToxMC4xMTIuNzEuMTU1OjY3ODldLFt2MjoxMC4xMTIuMTI3LjE0ODozMzAwLHYxOjEwLjExMi4xMjcuMTQ4OjY3ODldLFt2MjoxMC4xMTIuNzAuMjUzOjMzMDAsdjE6MTAuMTEyLjcwLjI1Mzo2Nzg5XSJ9</pre>
</div>
</div>
<div class="paragraph">
<p>Now get the site name for the <strong>secondary cluster</strong>:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc --kubeconfig site2/auth/kubeconfig get cephblockpools.ceph.rook.io replicapool -n openshift-storage -o jsonpath='{.status.mirroringInfo.summary.summary.site_name}{"\n"}'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>b888de61-8520-4381-a883-366e64bd400f-openshift-storage</pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Execute the following command on the <strong>primary cluster</strong>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>With the decoded value, create a secret on the <strong>primary cluster</strong>, using the site name of the <strong>secondary cluster</strong> from prior step as the secret name.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
<strong>Make sure to replace site name and token with the values from your cluster.</strong>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre>oc --kubeconfig site1/auth/kubeconfig -n openshift-storage \
  create secret generic b888de61-8520-4381-a883-366e64bd400f-openshift-storage \
  --from-literal=token=eyJmc2lkIjoiYjg4OGRlNjEtODUyMC00MzgxLWE4ODMtMzY2ZTY0YmQ0MDBmIiwiY2xpZW50X2lkIjoicmJkLW1pcnJvci1wZWVyIiwia2V5IjoiQVFDOCtWTmdkNURnQkJBQUd5S0l0VE9ac3FneVM3SEMrTXh5bGc9PSIsIm1vbl9ob3N0IjoiW3YyOjEwLjExMi43MS4xNTU6MzMwMCx2MToxMC4xMTIuNzEuMTU1OjY3ODldLFt2MjoxMC4xMTIuMTI3LjE0ODozMzAwLHYxOjEwLjExMi4xMjcuMTQ4OjY3ODldLFt2MjoxMC4xMTIuNzAuMjUzOjMzMDAsdjE6MTAuMTEyLjcwLjI1Mzo2Nzg5XSJ9 \
  --from-literal=pool=replicapool</pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>secret/b888de61-8520-4381-a883-366e64bd400f-openshift-storage created</pre>
</div>
</div>
<div class="paragraph">
<p>This completes the bootstrap process for the <strong>primary cluster</strong> to the <strong>secondary cluster</strong>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Repeat the process switching the steps for the <strong>secondary cluster</strong> and the <strong>primary cluster</strong>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To determine the name of the <code>rbd-mirror</code> secret that contains the bootstrap secret do the following:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc --kubeconfig site1/auth/kubeconfig get cephblockpool.ceph.rook.io/replicapool -n openshift-storage -ojsonpath='{.status.info.rbdMirrorBootstrapPeerSecretName}{"\n"}'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>pool-peer-token-replicapool</pre>
</div>
</div>
<div class="paragraph">
<p>The secret <code>pool-peer-token-replicapool</code> is the same as found in the <strong>secondary cluster</strong>. To find the decoded secret for the <strong>primary cluster</strong> do the following:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc --kubeconfig site1/auth/kubeconfig get secrets pool-peer-token-replicapool -n openshift-storage -o jsonpath='{.data.token}' | base64 -d</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>eyJmc2lkIjoiZjI4YWJjZjktMWZmZS00MWEwLWJkMmYtZjQzMDU2NGYwZWU1IiwiY2xpZW50X2lkIjoicmJkLW1pcnJvci1wZWVyIiwia2V5IjoiQVFDeStWTmdHQ25GQWhBQU5MNWQ1Zk9IQ1lMcTFYRDBSTkxMRHc9PSIsIm1vbl9ob3N0IjoiW3YyOjEwLjE2Ljc1LjE2NTozMzAwLHYxOjEwLjE2Ljc1LjE2NTo2Nzg5XSxbdjI6MTAuMTYuMTc2LjEwMTozMzAwLHYxOjEwLjE2LjE3Ni4xMDE6Njc4OV0sW3YyOjEwLjE2LjI0OC4yNDM6MzMwMCx2MToxMC4xNi4yNDguMjQzOjY3ODldIn0=</pre>
</div>
</div>
<div class="paragraph">
<p>Now get the site name for the <strong>primary cluster</strong>:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc --kubeconfig site1/auth/kubeconfig get cephblockpools.ceph.rook.io replicapool -n openshift-storage -o jsonpath='{.status.mirroringInfo.summary.summary.site_name}{"\n"}'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>f28abcf9-1ffe-41a0-bd2f-f430564f0ee5-openshift-storage</pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Execute the following command on the <strong>secondary cluster</strong>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
<strong>Make sure to replace site name and token with the values from your cluster.</strong>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre>oc --kubeconfig site2/auth/kubeconfig -n openshift-storage \
  create secret generic f28abcf9-1ffe-41a0-bd2f-f430564f0ee5-openshift-storage \
  --from-literal=token=eyJmc2lkIjoiZjI4YWJjZjktMWZmZS00MWEwLWJkMmYtZjQzMDU2NGYwZWU1IiwiY2xpZW50X2lkIjoicmJkLW1pcnJvci1wZWVyIiwia2V5IjoiQVFDeStWTmdHQ25GQWhBQU5MNWQ1Zk9IQ1lMcTFYRDBSTkxMRHc9PSIsIm1vbl9ob3N0IjoiW3YyOjEwLjE2Ljc1LjE2NTozMzAwLHYxOjEwLjE2Ljc1LjE2NTo2Nzg5XSxbdjI6MTAuMTYuMTc2LjEwMTozMzAwLHYxOjEwLjE2LjE3Ni4xMDE6Njc4OV0sW3YyOjEwLjE2LjI0OC4yNDM6MzMwMCx2MToxMC4xNi4yNDguMjQzOjY3ODldIn0= \
  --from-literal=pool=replicapool</pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>secret/f28abcf9-1ffe-41a0-bd2f-f430564f0ee5-openshift-storage created</pre>
</div>
</div>
<div class="paragraph">
<p>This completes the bootstrap process for the <strong>secondary cluster</strong> to the <strong>primary cluster</strong>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_create_rbd_mirror_custom_resource"><a class="anchor" href="#_create_rbd_mirror_custom_resource"></a>Create RBD Mirror Custom Resource</h5>
<div class="paragraph">
<p>Replication is handled by the <code>rbd-mirror</code> daemon. The <code>rbd-mirror</code> daemon is responsible for pulling image updates from the <strong><em>remote</em></strong> cluster, and applying them to images within the local cluster.</p>
</div>
<div class="paragraph">
<p>The <code>rbd-mirror</code> daemon(s) can be created using a custom resource (CR). There must be a <code>rbd-mirror</code> daemon or <strong>Pod</strong> created on the <strong>primary cluster</strong> and the <strong>secondary cluster</strong> using this CR:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: ceph.rook.io/v1
kind: CephRBDMirror
metadata:
  name: rbd-mirror
  namespace: openshift-storage
spec:
  # the number of rbd-mirror daemons to deploy
  count: 1
  # The affinity rules to apply to the mirror deployment
  placement:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: cluster.ocs.openshift.io/openshift-storage
            operator: Exists
    tolerations:
    - effect: NoSchedule
      key: node.ocs.openshift.io/storage
      operator: Equal
      value: "true"
  peers:
    secretNames:
      # list of Kubernetes Secrets containing the peer token
      - SECRET  # &lt;-- Fill in correct value
  resources:
    # The pod requests and limits
    limits:
      cpu: "1"
      memory: "2Gi"
    requests:
      cpu: "1"
      memory: "2Gi"</code></pre>
</div>
</div>
<div class="paragraph">
<p>To get the <code>secret</code> for the <strong>primary cluster</strong> do the following:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">SECRET=$(oc get secrets | grep openshift-storage | awk {'print $1}')
echo $SECRET</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>59b89021-3ee2-4a25-b087-b43ee80b3dde-openshift-storage</pre>
</div>
</div>
<div class="paragraph">
<p>Now create the <code>rbd-mirror</code> <strong>Pod</strong> for the <strong>primary site</strong>:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/red-hat-data-services/RDRhelper/master/docs/modules/manual/attachments/rbd-mirror.yaml | sed -e "s/SECRET/${SECRET}/g" | oc apply -f -</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>cephrbdmirror.ceph.rook.io/rbd-mirror created</pre>
</div>
</div>
<div class="paragraph">
<p>Check to see if the new`rbd-mirror` <strong>Pod</strong> is created and <code>Running</code>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get pods -l 'app=rook-ceph-rbd-mirror' -n openshift-storage</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>rook-ceph-rbd-mirror-a-57ccc68d88-lts87                           2/2     Running     0          5m</pre>
</div>
</div>
<div class="paragraph">
<p>Check the status of the <code>rbd-mirror</code> daemon health.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get cephblockpools.ceph.rook.io replicapool -n openshift-storage -o jsonpath='{.status.mirroringStatus.summary.summary}{"\n"}'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>{"daemon_health":"OK","health":"OK","image_health":"OK","states":{}}</pre>
</div>
</div>
<div class="paragraph">
<p>Now repeat process for <strong>secondary cluster</strong>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Make sure to do all steps above on the <strong>secondary cluster</strong>. The results for <code>SECRET</code> should be different than the <strong>primary cluster</strong> as a way to check you are on the <strong>secondary cluster</strong>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You have now completed the steps for configuring <strong>RBD Mirroring</strong> between the <strong>primary cluster</strong> and the <strong>secondary cluster</strong>. The next sections will cover how to enable Ceph RBD images (volumes) for mirroring data between clusters asynchronously. Also, using a sample application, detailed instructions will be provided on how to <code>failover</code> from <strong>primary cluster</strong> to the <strong>secondary cluster</strong> all the while preserving the persistent data.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_creating_mirror_storage_class_and_sample_application"><a class="anchor" href="#_creating_mirror_storage_class_and_sample_application"></a>1.3. Creating Mirror storage class and Sample application</h3>
<div class="paragraph">
<p>In order to fully understand the process of failover between clusters we need to deploy a sample application for validation after failover. Also, the default Ceph RBD <strong>StorageClasse</strong> created when ODF is installed is not useable for this testing given these instructions have you create a new <strong>CephBlockPool</strong> named <code>replicapool</code>.</p>
</div>
<div class="sect3">
<h4 id="_storageclass_for_volume_replication"><a class="anchor" href="#_storageclass_for_volume_replication"></a>1.3.1. Storageclass for volume replication</h4>
<div class="paragraph">
<p>Before any new ODF volumes are created for replication a new <strong>StorageClass</strong> needs to be created using <strong>CephBlockPool</strong> <code>replicapool</code> that was created in prior section.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>reclaimPolicy</code> needs to be <code>Retain</code> rather than <code>Delete</code> which is the usual default setting. This is needed to <strong><em>retain</em></strong> the image in Ceph even if the associated <strong>PVC</strong> and <strong>PV</strong> are deleted in OCP.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Example <strong>StorageClass</strong>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">allowVolumeExpansion: true
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ocs-storagecluster-ceph-mirror
parameters:
  clusterID: openshift-storage
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/controller-expand-secret-namespace: openshift-storage
  csi.storage.k8s.io/fstype: ext4
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
  csi.storage.k8s.io/node-stage-secret-namespace: openshift-storage
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: openshift-storage
  imageFeatures: layering
  imageFormat: "2"
  pool: replicapool
provisioner: openshift-storage.rbd.csi.ceph.com
reclaimPolicy: Retain
volumeBindingMode: Immediate</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now create the <strong>StorageClass</strong>:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/red-hat-data-services/RDRhelper/master/docs/modules/manual/attachments/ocs-storagecluster-ceph-mirror.yaml | oc apply -f -</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>storageclass.storage.k8s.io/ocs-storagecluster-ceph-mirror created</pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Make sure to also create the <code>ocs-storagecluster-ceph-mirror</code> <strong>StorageClass</strong> on the <strong>secondary cluster</strong> before proceeding.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_sample_application"><a class="anchor" href="#_sample_application"></a>1.3.2. Sample Application</h4>
<div class="paragraph">
<p>In order to test failing over from one OCP cluster to another we need a simple application to and verify that replication is working.</p>
</div>
<div class="paragraph">
<p>Start by creating a new project on the <strong>primary cluster</strong>:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc new-project my-database-app</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then use the <code>rails-pgsql-persistent</code> template to create the new application. The new <code>postgresql</code> volume will be claimed from the new <strong>StorageClass</strong>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/red-hat-storage/ocs-training/master/training/modules/ocs4/attachments/configurable-rails-app.yaml | oc new-app -p STORAGE_CLASS=ocs-storagecluster-ceph-mirror -p VOLUME_CAPACITY=5Gi -f -</code></pre>
</div>
</div>
<div class="paragraph">
<p>After the deployment is started you can monitor with these commands.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc status</code></pre>
</div>
</div>
<div class="paragraph">
<p>Check the PVC is created.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get pvc -n my-database-app</code></pre>
</div>
</div>
<div class="paragraph">
<p>This step could take 5 or more minutes. Wait until there are 2 <strong>Pods</strong> in
<code>Running</code> STATUS and 4 <strong>Pods</strong> in <code>Completed</code> STATUS as shown below.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">watch oc get pods -n my-database-app</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>NAME                                READY   STATUS      RESTARTS   AGE
postgresql-1-deploy                 0/1     Completed   0          5m48s
postgresql-1-lf7qt                  1/1     Running     0          5m40s
rails-pgsql-persistent-1-build      0/1     Completed   0          5m49s
rails-pgsql-persistent-1-deploy     0/1     Completed   0          3m36s
rails-pgsql-persistent-1-hook-pre   0/1     Completed   0          3m28s
rails-pgsql-persistent-1-pjh6q      1/1     Running     0          3m14s</pre>
</div>
</div>
<div class="paragraph">
<p>You can exit by pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>C</kbd></span>.</p>
</div>
<div class="paragraph">
<p>Once the deployment is complete you can now test the application and the
persistent storage on Ceph.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get route rails-pgsql-persistent -n my-database-app -o jsonpath --template="http://{.spec.host}/articles{'\n'}"</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will return a route similar to this one.</p>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>http://rails-pgsql-persistent-my-database-app.apps.cluster-ocs4-8613.ocs4-8613.sandbox944.opentlc.com/articles</pre>
</div>
</div>
<div class="paragraph">
<p>Copy your route (different than above) to a browser window to create articles.</p>
</div>
<div class="paragraph">
<p>Enter the <code>username</code> and <code>password</code> below to create articles and comments.
The articles and comments are saved in a PostgreSQL database which stores its
table spaces on the Ceph RBD volume provisioned using the
<code>ocs-storagecluster-ceph-mirror</code> <strong>StorageClass</strong> during the application
deployment.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>username: openshift
password: secret</pre>
</div>
</div>
<div class="paragraph">
<p>Once you have added a new article you can verify it exists in the <code>postgresql</code> database by issuing this command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -n my-database-app $(oc get pods -n my-database-app|grep postgresql | grep -v deploy | awk {'print $1}') psql -c "\c root" -c "\d+" -c "select * from articles"</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>You are now connected to database "root" as user "postgres".
                               List of relations
 Schema |         Name         |   Type   |  Owner  |    Size    | Description
--------+----------------------+----------+---------+------------+-------------
 public | ar_internal_metadata | table    | userXQR | 16 kB      |
 public | articles             | table    | userXQR | 16 kB      |
 public | articles_id_seq      | sequence | userXQR | 8192 bytes |
 public | comments             | table    | userXQR | 8192 bytes |
 public | comments_id_seq      | sequence | userXQR | 8192 bytes |
 public | schema_migrations    | table    | userXQR | 16 kB      |
(6 rows)

 id |     title     |                  body                  |         created_a
t         |         updated_at
----+---------------+----------------------------------------+------------------
----------+----------------------------
  2 | First Article | This is article #1 on primary cluster. | 2021-03-19 22:05:
07.255362 | 2021-03-19 22:05:07.255362
(1 row)</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_installing_oadp_for_kubernetes_resource_collection"><a class="anchor" href="#_installing_oadp_for_kubernetes_resource_collection"></a>1.4. Installing OADP for Kubernetes resource collection</h3>
<div class="paragraph">
<p>OADP (OpenShift APIs for Data Protection) is a community operator and is available in <strong>OperatorHub</strong>.</p>
</div>
<div class="paragraph">
<p>We will be using OADP for the <code>Backup</code> and <code>Restore</code> APIs for collecting the Kubernetes objects at a namespace level. The collection or backup of resources is needed to restore the application on the <strong>secondary cluster</strong>.</p>
</div>
<div class="sect3">
<h4 id="_installing_oadp_from_operatorhub"><a class="anchor" href="#_installing_oadp_from_operatorhub"></a>1.4.1. Installing OADP from OperatorHub</h4>
<div class="paragraph">
<p>First is to find OADP in <strong>OperatorHub</strong>. Login to your <strong>OpenShift Web Console</strong> and navigate to <strong>OperatorHub</strong>. Filter for <code>OADP</code> as shown below:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/OCP4-OADP-operatorhub-filter.png" alt="OperatorHub filter for OADP">
</div>
<div class="title">Figure 1. OperatorHub filter for OADP</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you are not finding OADP in <strong>OperatorHub</strong> most likely the <code>community-operator</code> catalogsource is not deployed in your cluster.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Select <code>Continue</code> on next screen.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/OCP4-OADP-operatorhub-continue.png" alt="OADP operator support statement">
</div>
<div class="title">Figure 2. OADP operator support statement</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
OADP is a community operator and as such is not supported by Red Hat. More information can be found at <a href="https://github.com/konveyor/oadp-operator" class="bare">github.com/konveyor/oadp-operator</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Select <code>Install</code> on next screen.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/OCP4-OADP-operatorhub-install.png" alt="OADP install screen">
</div>
<div class="title">Figure 3. OADP install screen</div>
</div>
<div class="paragraph">
<p>Now you will create the new namespace <code>oadp-operator</code> and install the OADP operator into this namespace. Select <code>Install</code> again.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/OCP4-OADP-operatorhub-install2.png" alt="OADP create namespace and install operator">
</div>
<div class="title">Figure 4. OADP create namespace and install operator</div>
</div>
<div class="paragraph">
<p>Wait for operator to install. When you see this screen the OADP operator is installed.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/OCP4-OADP-operator-installed.png" alt="OADP operator installed and ready">
</div>
<div class="title">Figure 5. OADP operator installed and ready</div>
</div>
<div class="paragraph">
<p>The next step is to create the <code>Velero</code> <strong>CustomResource</strong> or CR. For this you will need to have a <code>S3</code> compatible object bucket created that you know the <code>bucket name</code> as well as the credentials to access the bucket.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
It is not recommended to use ODF object buckets (MCG or RGW) as the <code>S3</code> <strong>BackingStorageLocation</strong> for <code>Velero</code> CR. If your remote or secondary clusters become unavailable and the <code>S3</code> bucket is created on that cluster there is no way to recover to alternate cluster.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_creating_bucket_credentials_secret"><a class="anchor" href="#_creating_bucket_credentials_secret"></a>1.4.2. Creating bucket credentials secret</h4>
<div class="paragraph">
<p>Before creating the  <code>Velero</code> CR you must create the <code>cloud-credentials</code> file with the creditials for your <code>S3</code> bucket. The format of the file needs to be this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[default]
aws_access_key_id=VELERO_ACCESS_KEY_ID
aws_secret_access_key=VELERO_SECRET_ACCESS_KEY</pre>
</div>
</div>
<div class="paragraph">
<p>Copy your unique credentials into file <code>cloud-credentials</code> and save file.</p>
</div>
<div class="paragraph">
<p>Now use this new <code>cloud-credentials</code> file to create a new <strong>Secret</strong>. Replace <code>&lt;CREDENTIALS_FILE_PATH&gt;</code> with path to file you created with <code>S3</code> credentials.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>oc create secret generic cloud-credentials --namespace oadp-operator --from-file cloud=&lt;CREDENTIALS_FILE_PATH&gt;/cloud-credentials</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_creating_velero_resource"><a class="anchor" href="#_creating_velero_resource"></a>1.4.3. Creating Velero resource</h4>
<div class="paragraph">
<p>The velero YAML file needs to be modified to be correct for your <code>S3</code> bucket. The example is for a <code>S3</code> bucket on <strong>AWS</strong> saved as file <code>velero-aws.yaml</code>. It is recommended to use an object bucket <code>off-platform</code> meaning not backed by storage in the <strong>primary cluster</strong> or the <strong>secondary cluster</strong>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Your velero YAML file will be slightly different if using a <code>S3</code> object bucket from a different provider (GCP, Azure), from an external Ceph cluster with <code>RGW</code>, or from ODF <code>MCG</code>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: konveyor.openshift.io/v1alpha1
kind: Velero
metadata:
  name: oadp-velero
  namespace: oadp-operator
spec:
  olm_managed: true
  backup_storage_locations:
    - config:
        profile: default
        region: us-east-2  # &lt;-- Modify to bucket AWS region or region for your provider
      credentials_secret_ref:
        name: cloud-credentials
        namespace: oadp-operator
      name: default
      object_storage:
        bucket: oadp-xxxxxx # Modify to your bucket name
        prefix: velero
      provider: aws
  default_velero_plugins:
    - aws
    - openshift
  enable_restic: false</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once you have your unique values copied into your YAML file create the <code>Velero</code> CR.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If wanting to us a <code>MCG</code> object bucket instead of a bucket <code>off-platform</code> (i.e. AWS) as recommended, reference these instructions <a href="https://github.com/konveyor/oadp-operator/blob/master/docs/noobaa/install_oadp_noobaa.md" class="bare">github.com/konveyor/oadp-operator/blob/master/docs/noobaa/install_oadp_noobaa.md</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre>oc create -f velero-aws.yaml -n oadp-operator</pre>
</div>
</div>
<div class="paragraph">
<p>Validate that the <code>velero</code> pod is <code>Running</code> and that the <strong>BackingStorageLocation</strong> have been created as well that has the details to access your <code>S3</code> bucket for Kubernetes object storage.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get pods,backupstoragelocation -n oadp-operator</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>NAME                                           READY   STATUS    RESTARTS   AGE
pod/oadp-default-aws-registry-88f556c5-2mk6h   1/1     Running   0          4m59s
pod/oadp-operator-6bb9fb6cfc-mc6vw             1/1     Running   0          49m
pod/velero-6c6fd6d84d-mbct9                    1/1     Running   0          5m3s

NAME                                      PHASE       LAST VALIDATED   AGE
backupstoragelocation.velero.io/default   Available   9s               5m1s</pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Repeat these steps and install <strong>OADP</strong> on the <strong>secondary cluster</strong>. Make sure to use the same <code>S3</code> bucket and credentials as for the <strong>primary cluster</strong> when creating the <code>Velero</code> CR.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_failover_to_secondary_cluster"><a class="anchor" href="#_failover_to_secondary_cluster"></a>1.5. Failover to Secondary cluster</h3>
<div class="paragraph">
<p>The setup and configuration steps in the prior section have prepared the environment to support a failover event from the <strong>primary cluster</strong> to the <strong>secondary cluster</strong>. In our case this will be for just one namespace (my-database-app) that includes restoring the Kubernetes objects and persistent data stored in <strong>PVCs</strong>. The following steps will be followed for the failover:</p>
</div>
<div class="olist arabic">
<ol class="arabic" start="1">
<li>
<p>Using the toolbox enable image(s) for replication via snapshot to peer cluster.</p>
</li>
<li>
<p>Use OADP and the <code>Backup</code> CR to collect Kubernetes objects for application namespace.</p>
</li>
<li>
<p>Scale application deployment down to take application offline.</p>
</li>
<li>
<p>Using the <code>toolbox</code> <strong>demote</strong> the storage for the application on the <strong>primary cluster</strong>.</p>
</li>
<li>
<p>Using the <code>toolbox</code> <strong>promote</strong> the storage on the <strong>secondary cluster</strong>.</p>
</li>
<li>
<p>Use OADP and the <code>Restore</code> CR to bring the application online using collected Kubernetes objects.</p>
</li>
<li>
<p>Verify use of the application on the <strong>secondary cluster</strong>.</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="_installing_the_toolbox_for_ceph_commands"><a class="anchor" href="#_installing_the_toolbox_for_ceph_commands"></a>1.5.1. Installing the toolbox for Ceph commands</h4>
<div class="paragraph">
<p>Since the Rook-Ceph <strong>toolbox</strong> is not shipped with ODF you will need to deploy it
manually because a few steps of the failover process require use of Ceph commands today.</p>
</div>
<div class="paragraph">
<p>You can patch the <code>OCSInitialization ocsinit</code> to create the <strong>toolbox</strong> using the following command line:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc patch OCSInitialization ocsinit -n openshift-storage --type json --patch  '[{ "op": "replace", "path": "/spec/enableCephTools", "value": true }]'</code></pre>
</div>
</div>
<div class="paragraph">
<p>After the <code>rook-ceph-tools</code> <strong>Pod</strong> is <code>Running</code> you can access the <strong>toolbox</strong>
like this:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">TOOLS_POD=$(oc get pods -n openshift-storage -l app=rook-ceph-tools -o name)
oc rsh -n openshift-storage $TOOLS_POD</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once inside the <strong>toolbox</strong> try out the following Ceph commands:</p>
</div>
<div class="paragraph">
<p>Check the health of the Ceph cluster first.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">ceph health</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>HEALTH_OK</pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
Make sure that <code>HEALTH_OK</code> is the status before proceeding.
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool mirror pool status</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>health: OK
daemon health: OK
image health: OK
images: 0 total</pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool mirror snapshot schedule ls</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>every 5m</pre>
</div>
</div>
<div class="paragraph">
<p>You can exit the toolbox by either pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>D</kbd></span> or by executing exit.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">exit</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Make sure to repeat these steps on the <strong>secondary cluster</strong> as well and logon to the <strong>toolbox</strong> and run the same Ceph commands to validate the health of the cluster and mirroring.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_enable_volumes_for_snapshot_replication"><a class="anchor" href="#_enable_volumes_for_snapshot_replication"></a>1.5.2. Enable volumes for snapshot replication</h4>
<div class="paragraph">
<p>In order to have persistent data replicated for a particular application the volume(s) or images have to be enabled for mirroring. This is currently done using Ceph commands after logging into the <strong>toolbox</strong>.</p>
</div>
<div class="paragraph">
<p>To map a <strong>PVC</strong> name to a <code>image</code> name in Ceph you can use these commands.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Change the <strong>PVC</strong> name in the command if your name is different than <code>postgresql</code>.
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">CSIVOL=$(kubectl get pv $(kubectl get pv | grep postgresql | awk '{ print $1 }') -o jsonpath='{.spec.csi.volumeHandle}' | cut -d '-' -f 6- | awk '{print "csi-vol-"$1}')
echo $CSIVOL</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>csi-vol-94953897-88fc-11eb-b175-0a580a061092</pre>
</div>
</div>
<div class="paragraph">
<p>Now that you know your <code>image</code> name(s), login to the <strong>toolbox</strong> again on the <strong>primary cluster</strong>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">TOOLS_POD=$(oc get pods -n openshift-storage -l app=rook-ceph-tools -o name)
oc rsh -n openshift-storage $TOOLS_POD</code></pre>
</div>
</div>
<div class="paragraph">
<p>List the images in the <strong>CephBlockPool</strong> replicapool.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool ls</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>csi-vol-94953897-88fc-11eb-b175-0a580a061092</pre>
</div>
</div>
<div class="paragraph">
<p>In this case there is only one image or volume that was created for the <code>postgresql</code> persistent data storage. This is the image you want to enable for mirroring on the <strong>primary cluster</strong>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Your image name will be different. Use your image name for following commands.
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool mirror image enable csi-vol-94953897-88fc-11eb-b175-0a580a061092 snapshot</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>Mirroring enabled</pre>
</div>
</div>
<div class="paragraph">
<p>You can now get more information about image mirroring by doing this command on the <strong>primary cluster</strong>,</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool info csi-vol-94953897-88fc-11eb-b175-0a580a061092</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output from <strong>primary cluster</strong>:</div>
<div class="content">
<pre>rbd image 'csi-vol-94953897-88fc-11eb-b175-0a580a061092':
	size 5 GiB in 1280 objects
	order 22 (4 MiB objects)
	snapshot_count: 1
	id: ee409072562b
	block_name_prefix: rbd_data.ee409072562b
	format: 2
	features: layering
	op_features:
	flags:
	create_timestamp: Fri Mar 19 21:46:38 2021
	access_timestamp: Fri Mar 19 21:46:38 2021
	modify_timestamp: Fri Mar 19 21:46:38 2021
	mirroring state: enabled
	mirroring mode: snapshot
	mirroring global id: 8cd6c7e8-a92b-4d1c-bcac-d9c9cd234980
	mirroring primary: true  <i class="conum" data-value="1"></i><b>(1)</b></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Currently storage is promoted on <strong>primary cluster</strong></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To validate the mirroring or replication is working you can logon to the <strong>toolbox</strong> on the <strong>secondary cluster</strong> and run the same command for the exact same image name which should now be replicated to the peer cluster.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool info csi-vol-94953897-88fc-11eb-b175-0a580a061092</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output from <strong>secondary cluster</strong>:</div>
<div class="content">
<pre>rbd image 'csi-vol-94953897-88fc-11eb-b175-0a580a061092':
	size 5 GiB in 1280 objects
	order 22 (4 MiB objects)
	snapshot_count: 1
	id: 74c39ad8d17a
	block_name_prefix: rbd_data.74c39ad8d17a
	format: 2
	features: layering, non-primary
	op_features:
	flags:
	create_timestamp: Sun Mar 21 00:49:58 2021
	access_timestamp: Sun Mar 21 00:49:58 2021
	modify_timestamp: Sun Mar 21 00:49:58 2021
	mirroring state: enabled
	mirroring mode: snapshot
	mirroring global id: 8cd6c7e8-a92b-4d1c-bcac-d9c9cd234980
	mirroring primary: false  <i class="conum" data-value="1"></i><b>(1)</b></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Currently storage is demoted on <strong>secondary cluster</strong></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>These steps would be repeated for every image that you want to mirror via snapshot to the peer cluster. For this example the snapshot interval is <code>1 hour</code> and was configured in the <code>replicapool</code> <strong>CephBlockPool</strong> CR.</p>
</div>
<div class="paragraph">
<p>You can exit the toolbox by either pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>D</kbd></span> or by executing exit.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">exit</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_creating_kubernetes_resource_backup"><a class="anchor" href="#_creating_kubernetes_resource_backup"></a>1.5.3. Creating Kubernetes resource backup</h4>
<div class="paragraph">
<p>The Kubernetese objects or resources for the OpenShift namespace <code>my-database-app</code> have to be backed up and stored in a location where the <strong>secondary cluster</strong> can access. In this case using the <code>OADP</code> or <code>Velero</code> <strong>Backup</strong> API is how this will be done.</p>
</div>
<div class="paragraph">
<p>Here is a sample <code>backup.yaml</code> file for the sample application:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
  namespace: oadp-operator
  name: backup1
spec:
  includedNamespaces:
  - my-database-app
  excludedResources:
  - imagetags.image.openshift.io
  snapshotVolumes: false</code></pre>
</div>
</div>
<div class="paragraph">
<p>Given the persistent data is going to be mirrored or replicated from the <strong>primary cluster</strong> to the <strong>secondary cluster</strong> we do not need the <code>OADP</code> <strong>Backup</strong> to include this data and therefore set <code>snapshotVolumes: false</code>.</p>
</div>
<div class="paragraph">
<p>There is one additional resource to exclude that will be done by adding a label to the specific <code>configmap</code>. This is needed, excluding this resource for the <strong>Backup</strong>, because this <code>configmap</code> includes a <code>service-ca.crt</code> that needs to be uniquely created on the <strong>secondary cluster</strong> (not copied).</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label -n my-database-app configmaps rails-pgsql-persistent-1-ca velero.io/exclude-from-backup=true</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>configmap/rails-pgsql-persistent-1-ca labeled</pre>
</div>
</div>
<div class="paragraph">
<p>Now create the <strong>Backup</strong> for <code>my-database-app</code> namespace.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/red-hat-data-services/RDRhelper/master/docs/modules/manual/attachments/backup.yaml | oc apply -f -</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>backup.velero.io/backup1 created</pre>
</div>
</div>
<div class="paragraph">
<p>Verify the <strong>Backup</strong> completed successfully to your <code>S3</code> object bucket target using the following command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe backup backup1 -n oadp-operator</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>Name:         backup1
Namespace:    oadp-operator
Labels:       velero.io/storage-location=default
Annotations:  velero.io/source-cluster-k8s-gitversion: v1.20.0+bd9e442
              velero.io/source-cluster-k8s-major-version: 1
              velero.io/source-cluster-k8s-minor-version: 20
API Version:  velero.io/v1
Kind:         Backup

[...]
Spec:
  Default Volumes To Restic:  false
  Excluded Resources:  <i class="conum" data-value="1"></i><b>(1)</b>
    imagetags.image.openshift.io
  Included Namespaces:
    my-database-app  <i class="conum" data-value="2"></i><b>(2)</b>
  Snapshot Volumes:  false
  Storage Location:  default
  Ttl:               720h0m0s
Status:
  Completion Timestamp:  2021-03-22T19:18:57Z
  Expiration:            2021-04-21T19:17:20Z
  Format Version:        1.1.0
  Phase:                 Completed  <i class="conum" data-value="3"></i><b>(3)</b>
  Progress:
    Items Backed Up:  63  <i class="conum" data-value="4"></i><b>(4)</b>
    Total Items:      63
  Start Timestamp:    2021-03-22T19:17:20Z
  Version:            1
Events:               &lt;none&gt;</pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Excluded resources for backup</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Namespace for which resources copied to object bucket</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Successul backup with Completed status</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The number of Kubernetes resources backed up</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_scaling_application_down_on_primary_cluster"><a class="anchor" href="#_scaling_application_down_on_primary_cluster"></a>1.5.4. Scaling application down on primary cluster</h4>
<div class="paragraph">
<p>The reason for Disaster Recovery (DR) of an OCP cluster or application would usually happen because the <strong>primary cluster</strong> has become partially or completely unavailable. In order to simulate this behavior for our sample application the easiest way is to scale the deployments down on the <strong>primary cluster</strong> so as to make the application unavailable.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s take a look at the <strong>DeploymentConfig</strong> for our application.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get deploymentconfig -n my-database-app</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>NAME                     REVISION   DESIRED   CURRENT   TRIGGERED BY
postgresql               1          1         1         config,image(postgresql:10)
rails-pgsql-persistent   1          1         1         config,image(rails-pgsql-persistent:latest)</pre>
</div>
</div>
<div class="paragraph">
<p>There are two <strong>DeploymentConfig</strong> to scale to zero.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc scale deploymentconfig postgresql -n my-database-app --replicas=0</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>deploymentconfig.apps.openshift.io/postgresql scaled</pre>
</div>
</div>
<div class="paragraph">
<p>Now scale the second deployment to zero.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc scale deploymentconfig rails-pgsql-persistent -n my-database-app --replicas=0</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>deploymentconfig.apps.openshift.io/rails-pgsql-persistent scaled</pre>
</div>
</div>
<div class="paragraph">
<p>Check to see the <strong>Pods</strong> are deleted. The following command should return <strong><em>no</em></strong> results if both <strong>DeploymentConfig</strong> are scaled to zero.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get pods -n my-database-app | grep Running</code></pre>
</div>
</div>
<div class="paragraph">
<p>Test that the application is down on the <strong>primary cluster</strong> by refreshing the route in your browser or get route again and copy to browser tab.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get route rails-pgsql-persistent -n my-database-app -o jsonpath --template="http://{.spec.host}/articles{'\n'}"</code></pre>
</div>
</div>
<div class="paragraph">
<p>You show see something like this now.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/sample-app-down-primary.png" alt="Sample application is offline">
</div>
<div class="title">Figure 6. Sample application is offline</div>
</div>
</div>
<div class="sect3">
<h4 id="_demoting_and_promoting_storage_to_alternate_site"><a class="anchor" href="#_demoting_and_promoting_storage_to_alternate_site"></a>1.5.5. Demoting and Promoting storage to alternate site</h4>
<div class="paragraph">
<p>In order to failover the storage on the <strong>primary cluster</strong> must be <code>demoted</code> and the storage on the <strong>secondary cluster</strong> must be `promoted. This is currently done on a per image basis using the <strong>toolbox</strong>.</p>
</div>
<div class="paragraph">
<p>To map a <strong>PVC</strong> name to a <code>image</code> name in Ceph you can use these commands.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Change the <strong>PVC</strong> name in the command if your name is different than <code>postgresql</code>.
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">CSIVOL=$(kubectl get pv $(kubectl get pv | grep postgresql | awk '{ print $1 }') -o jsonpath='{.spec.csi.volumeHandle}' | cut -d '-' -f 6- | awk '{print "csi-vol-"$1}')
echo $CSIVOL</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>csi-vol-94953897-88fc-11eb-b175-0a580a061092</pre>
</div>
</div>
<div class="paragraph">
<p>Now that you know the <code>image</code> name(s), logon again to the <strong>toolbox</strong> on the <strong>primary cluster</strong> to use Ceph commands.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">TOOLS_POD=$(oc get pods -n openshift-storage -l app=rook-ceph-tools -o name)
oc rsh -n openshift-storage $TOOLS_POD</code></pre>
</div>
</div>
<div class="paragraph">
<p>List the images in the <strong>CephBlockPool</strong> replicapool.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool ls</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>csi-vol-94953897-88fc-11eb-b175-0a580a061092</pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Your image name will be different. Use your image name for following commands.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>First <code>demote</code> the <code>postgresql</code> image on the <strong>primary cluster</strong>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool mirror image demote csi-vol-94953897-88fc-11eb-b175-0a580a061092</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>Image demoted to non-primary</pre>
</div>
</div>
<div class="paragraph">
<p>Now logon to the <strong>toolbox</strong> on the <strong>secondary cluster</strong> and <code>promote</code> the <code>postgresql</code> image.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool mirror image promote csi-vol-94953897-88fc-11eb-b175-0a580a06109</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>Image promoted to primary</pre>
</div>
</div>
<div class="paragraph">
<p>Using the <strong>toolbox</strong> on the <strong>secondary cluster</strong> validate the image is now <code>promoted</code>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool info csi-vol-94953897-88fc-11eb-b175-0a580a061092</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output from <strong>secondary cluster</strong>:</div>
<div class="content">
<pre>rbd image 'csi-vol-94953897-88fc-11eb-b175-0a580a061092':
	size 5 GiB in 1280 objects
	order 22 (4 MiB objects)
	snapshot_count: 1
	id: 74c39ad8d17a
	block_name_prefix: rbd_data.74c39ad8d17a
	format: 2
	features: layering
	op_features:
	flags:
	create_timestamp: Sun Mar 21 00:49:58 2021
	access_timestamp: Sun Mar 21 00:49:58 2021
	modify_timestamp: Sun Mar 21 00:49:58 2021
	mirroring state: enabled
	mirroring mode: snapshot
	mirroring global id: 8cd6c7e8-a92b-4d1c-bcac-d9c9cd234980
	mirroring primary: true  <i class="conum" data-value="1"></i><b>(1)</b></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Image is now promoted on <strong>secondary cluster</strong></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>These steps would be repeated for every image that you want to <code>demote</code> and <code>promote</code> to the <strong>secondary cluster</strong>.</p>
</div>
<div class="paragraph">
<p>Also validate that the <code>mirror pool status</code> is healthy on the <strong>secondary cluster</strong>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rbd -p replicapool mirror pool status</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>health: OK
daemon health: OK
image health: OK
images: 1 total
    1 replaying</pre>
</div>
</div>
<div class="paragraph">
<p>You can exit the toolbox by either pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>D</kbd></span> or by executing exit.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">exit</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_restoring_application_to_secondary_cluster"><a class="anchor" href="#_restoring_application_to_secondary_cluster"></a>1.5.6. Restoring application to secondary cluster</h4>
<div class="paragraph">
<p>The last step in the process to failover to the <strong>secondary cluster</strong> is to now use <code>OADP</code> and the <strong>Restore</strong> CR to copy the Kubernetes objects to the <strong><em>remote</em></strong> cluster. The persistent data is already <code>mirrored</code> to the <strong>secondary cluster</strong> from the <strong>primary cluster</strong> and therefore does not need to be copied.</p>
</div>
<div class="paragraph">
<p>Here is a the <code>restore.yaml</code> file for the sample application:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: velero.io/v1
kind: Restore
metadata:
  namespace: oadp-operator
  name: restore1
spec:
  backupName: backup1
  includedNamespaces:
  - my-database-app</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now create the <strong>Restore</strong> on the <strong>secondary cluster</strong> for the <code>my-database-app</code> namespace. You notice in the <strong>Restore</strong> that the <code>backup1</code> created earlier is referenced.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Make sure to issue this command on the <strong>secondary cluster</strong>. The namespace <code>my-database-app</code> should not exist on the <strong>secondary cluster</strong> yet.
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/red-hat-data-services/RDRhelper/master/docs/modules/manual/attachments/restore.yaml | oc apply -f -</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>restore.velero.io/restore1 created</pre>
</div>
</div>
<div class="paragraph">
<p>Verify the <strong>Restore</strong> completed successfully from your <code>S3</code> object bucket target using the following command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe restore restore1 -n oadp-operator</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>Name:         restore1
Namespace:    oadp-operator
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;
API Version:  velero.io/v1
Kind:         Restore

[...]
Spec:
  Backup Name:  backup1  <i class="conum" data-value="1"></i><b>(1)</b>
  Excluded Resources:
    nodes
    events
    events.events.k8s.io
    backups.velero.io
    restores.velero.io
    resticrepositories.velero.io
  Included Namespaces:
    my-database-app <i class="conum" data-value="2"></i><b>(2)</b>
Status:
  Completion Timestamp:  2021-03-23T23:51:43Z
  Phase:                 Completed  <i class="conum" data-value="3"></i><b>(3)</b>
  Start Timestamp:       2021-03-23T23:51:28Z
  Warnings:              7
Events:                  &lt;none&gt;</pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Name of backup used for restore operation</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Namespace to be restored from backup1</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Successul restore with Completed status</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Check to see that the <strong>PODs</strong> and <strong>PVC</strong> are created correctly in `my-database-app`namespace on <strong>secondary cluster</strong>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get pods,pvc -n my-database-app</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>NAME                                    READY   STATUS      RESTARTS   AGE
pod/postgresql-1-deploy                 0/1     Completed   0          9m10s
pod/postgresql-1-nld26                  1/1     Running     0          9m7s
pod/rails-pgsql-persistent-1-build      0/1     Completed   0          9m4s
pod/rails-pgsql-persistent-1-deploy     0/1     Completed   0          9m4s
pod/rails-pgsql-persistent-1-hook-pre   0/1     Completed   0          9m1s
pod/rails-pgsql-persistent-2-4b28n      1/1     Running     0          6m39s
pod/rails-pgsql-persistent-2-deploy     0/1     Completed   0          7m1s
pod/rails-pgsql-persistent-2-hook-pre   0/1     Completed   0          6m58s

NAME                               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                     AGE
persistentvolumeclaim/postgresql   Bound    pvc-c1b313c2-8e96-45b0-b9c8-57864b9437e7   5Gi        RWO            ocs-storagecluster-ceph-mirror   9m13s</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_verifying_application"><a class="anchor" href="#_verifying_application"></a>1.5.7. Verifying application</h4>
<div class="paragraph">
<p>To verify the application on the <strong>secondary cluster</strong> you will want to access the application again and create a new article.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get route rails-pgsql-persistent -n my-database-app -o jsonpath --template="http://{.spec.host}/articles{'\n'}"</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will return a route similar to this one.</p>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>http://rails-pgsql-persistent-my-database-app.apps.cluster-ocs4-8613.ocs4-8613.sandbox944.opentlc.com/articles</pre>
</div>
</div>
<div class="paragraph">
<p>Copy your route (different than above) to a browser window to create another article on the <strong>secondary cluster</strong>.</p>
</div>
<div class="paragraph">
<p>Enter the <code>username</code> and <code>password</code> below to create articles and comments.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>username: openshift
password: secret</pre>
</div>
</div>
<div class="paragraph">
<p>Once you have added a new article you can verify it exists in the <code>postgresql</code> database by issuing this command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -n my-database-app $(oc get pods -n my-database-app|grep postgresql | grep -v deploy | awk {'print $1}') psql -c "\c root" -c "select * from articles"</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre>You are now connected to database "root" as user "postgres".
 id |     title      |                   body                   |         create
d_at         |         updated_at
----+----------------+------------------------------------------+---------------
-------------+----------------------------
  2 | First Article  | This is article #1 on primary cluster.   | 2021-03-19 22:
05:07.255362 | 2021-03-19 22:05:07.255362
  3 | Second Article | This is article #2 on secondary cluster. | 2021-03-22 23:
29:24.051123 | 2021-03-22 23:29:24.051123
(2 rows)</pre>
</div>
</div>
<div class="paragraph">
<p>You should see your first article created on the <strong>primary cluster</strong> and the second article created on the <strong>secondary cluster</strong>. The application is now verified and the failover is completed.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If you want to delete the <code>my-database-app</code> project from the <strong>secondary cluster</strong> and the <strong>primary cluster</strong> it is important to modify the associated <strong>PV</strong> <code>reclaimPolicy</code> from <code>Retain</code> to <code>Delete</code>. Then, when the <code>my-database-app</code> project and <strong>PVC</strong> is deleted, the associated <strong>PV</strong> will be deleted as well as the associated image in Ceph.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_failback_to_primary_cluster"><a class="anchor" href="#_failback_to_primary_cluster"></a>1.6. Failback to Primary cluster</h3>
<div class="paragraph">
<p>In order to failback to the <strong>primary cluster</strong> from the <strong>secondary cluster</strong> repeat the steps for failover except reverse the order between primary and secondary. If the <strong>primary cluster</strong> has been offline for some amount of time it could be necessary to either <code>force promote</code> or <code>resync</code> the image{s} using the <strong>toolbox</strong>.</p>
</div>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <a class="navbar-item" href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage" target="_blank">
      <img src="../../_/img/header_logo.svg" alt="Red Hat Data Services">
  </a>
</footer>
<script src="../../_/js/site.js"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
  </body>
</html>
